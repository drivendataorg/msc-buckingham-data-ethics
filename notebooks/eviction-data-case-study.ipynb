{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Ethics Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The goals of this notebook exercise are (1) to practice integrating the `deon` checklist into your code, and (2) to learn how to use a few basic data science tools in python.\n",
    "\n",
    "This notebook is for the Eviction Data Case Study exercise in the \"Actionable Ethics for Data Scientists\" workshop for the data science MSc at the University of Buckingham.\n",
    "\n",
    "Instructions\n",
    "\n",
    "- We'll walk through the notebook as a group, and break for independent work where there is a <span style=\"color:green\">**\\*\\*bolded green heading for \"Activity\" or \"Discussion\"\\*\\***</span>.\n",
    "\n",
    "- If you need help debugging during any of the exercises, post in the Teams thread for this workshop or send a direct message to one of the DrivenData team members. **We encourage you to work together!**\n",
    "\n",
    "- There is a more comprehensive version of the case study notebook in `notebooks/eviction-data-case-study-reference.ipynb`. You can refer to this if you are stumped during any of the coding exercises, but we strongly encourage solving problems on your own first!\n",
    "\n",
    "**We will not discuss every item on the deon checklist - items have been chosen that illustrate interesting points or coding challenges.** In real-world setting, you'll want to integrate the full deon checklist into your coding. You can see an example of this in the workshop repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the past five decades, [housing costs have risen faster than incomes](http://www.jchs.harvard.edu/state-nations-housing-2018), low-cost housing has been disappearing from the market, and racial disparities in homeownership rates have deepened. This has put many in a perilous situation. As the [Eviction Lab](https://evictionlab.org/why-eviction-matters/#affordable-housing-crisis) explains:\n",
    "\n",
    "> Today, most poor renting families spend at least half of their income on housing costs, with one in four of those families spending over 70 percent of their income just on rent and utilities. Only one in four families who qualify for affordable housing programs get any kind of help. Under those conditions, it has become harder for low-income families to keep up with rent and utility costs, and a growing number are living one misstep or emergency away from eviction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A non-profit dedicated to helping people at risk of eviction in California has tasked us to build a model to estimate the number of eviction cases by geography, based on socioeconomic data. They would like to use these estimates to help them prioritize where to commit funding and resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a subset of the eviction dataset published by the [Eviction Lab](https://evictionlab.org/) at Princeton University. The subset is the census-tract-level aggregates for only tracts in the state of California. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "Import necessary python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import wget\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://drivendata-public-assets.s3.amazonaws.com/odsc-west-2019/california-tracts.csv\"\n",
    "DATA_PATH = \"../data/raw/california-tracts.csv\"\n",
    "\n",
    "# Set standard fig size for plots\n",
    "FIGSIZE = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_PATH):\n",
    "    # Download data\n",
    "    wget.download(url=DATA_URL, out=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"\\nData types:\\n\", df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = non-NaN observations; size = all observations\n",
    "df.groupby(\"year\").agg(\n",
    "    count=(\"eviction-rate\", \"count\"), size=(\"eviction-rate\", \"size\")\n",
    ").transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Dictionary\n",
    "DATA_DICT_URL = \"https://drivendata-public-assets.s3.amazonaws.com/odsc-west-2019/DATA_DICTIONARY.txt\"\n",
    "DATA_DICT_PATH = \"../references/DATA_DICTIONARY.txt\"\n",
    "\n",
    "if not os.path.exists(DATA_DICT_PATH):\n",
    "    # Download data dictionary\n",
    "    wget.download(url=DATA_DICT_URL, out=DATA_DICT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $DATA_DICT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Collection\n",
    "\n",
    "## B. Data Storage\n",
    "\n",
    "We won't go into data collection or data storage in detail in this exercise. To see an integration of these sections' checklists with the eviction case study, see the reference notebook in the workshop repository.\n",
    "\n",
    "*One note on the data:* The history around defining racial categories is complex, flawed, and nuanced. For the purposes of this activity, we will accept the race-based categories in the data as is. In a real-world context, reflecting on the broader context in greater detail would be worthwhile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go into missing perspectives in detail in this exercise. For more detail, see the reference notebook in the workshop repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into the number of missing values for a handful of relevant columns\n",
    "df[[\"low-flag\", \"imputed\", \"evictions\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many observations have the low-flag?\n",
    "print(f\"Proportion of observations with low-flag: {df['low-flag'].mean():.2f}\")\n",
    "df[\"low-flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many observations have the imputed flag?\n",
    "print(f\"Proportion of observations with imputed flag: {df['imputed'].mean():.2f}\")\n",
    "df[\"imputed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many tracts are missing the number of evictions?\n",
    "print(f\"Proportion of Evictions Counts that are NA: {df['evictions_is_na'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the eviction values generally?\n",
    "df.evictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the general values of the race columns?\n",
    "race_cols = [\n",
    "    \"pct-white\",\n",
    "    \"pct-af-am\",\n",
    "    \"pct-hispanic\",\n",
    "    \"pct-am-ind\",\n",
    "    \"pct-asian\",\n",
    "    \"pct-nh-pi\",\n",
    "    \"pct-multiple\",\n",
    "    \"pct-other\",\n",
    "]\n",
    "df[race_cols].describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pairwise correlation of some columns against race percentage columns\n",
    "cols_to_correlate = [\"evictions\", \"median-household-income\", \"imputed\", \"low-flag\"]\n",
    "correlation_df = (\n",
    "    df[race_cols + cols_to_correlate].corr().loc[race_cols, cols_to_correlate]\n",
    ")\n",
    "correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the above correlations.\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "sns.heatmap(\n",
    "    correlation_df.sort_values(\"evictions\"),\n",
    "    annot=True,\n",
    "    fmt=\"g\",\n",
    "    cmap=\"RdBu_r\",\n",
    "    vmin=-0.5,\n",
    "    vmax=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not going to spend time in this exercise looking at examples of poor visualizations, but this is a good check to do for real projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly not applicable. We have no PII, but we do have some tracts with few observations. We need to be mindful of those and maybe exclude them from visualizations or combine them with neighboring tracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, all of our code is contained in this notebook. For real projects, this is an important point to consider in more depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-profit wants their decision-making to be race-blind, so they ask for the population race percentage features to not be included in the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VAR = \"evictions\"\n",
    "FEATURE_VARS = [\n",
    "    \"year\",\n",
    "    \"population\",\n",
    "    \"poverty-rate\",\n",
    "    \"median-property-value\",\n",
    "    \"renter-occupied-households\",\n",
    "    \"pct-renter-occupied\",\n",
    "    \"median-gross-rent\",\n",
    "    \"median-household-income\",\n",
    "    \"rent-burden\",\n",
    "    ## Don't include race features\n",
    "    #'pct-white' , 'pct-af-am', 'pct-hispanic', 'pct-am-ind',\n",
    "    #'pct-asian', 'pct-nh-pi', 'pct-multiple', 'pct-other'\n",
    "    ## Also don't include features directly related to the target variable\n",
    "    # 'eviction-filings', 'eviction-rate', 'eviction-filing-rate'\n",
    "]\n",
    "GROUP_VAR = \"GEOID\"  # Prevent leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original Shape: {df.shape}\")\n",
    "# Drop NAs in target variable\n",
    "df_modeling = df.dropna(subset=[TARGET_VAR]).copy()\n",
    "df_modeling.reset_index(inplace=True)\n",
    "print(f\"Shape without NAs: {df_modeling.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit, cross_validate\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling.loc[:, TARGET_VAR].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train-test split for model evaluation later\n",
    "split = GroupShuffleSplit(test_size=0.20, n_splits=2, random_state=36).split(\n",
    "    df_modeling, groups=df_modeling.loc[:, GROUP_VAR]\n",
    ")\n",
    "\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "df_train = df_modeling.loc[train_inds, :]\n",
    "df_test = df_modeling.loc[test_inds, :]\n",
    "\n",
    "X_train = df_train.loc[:, FEATURE_VARS].values\n",
    "y_train = df_train.loc[:, TARGET_VAR].values\n",
    "\n",
    "X_test = df_test.loc[:, FEATURE_VARS].values\n",
    "y_test = df_test.loc[:, TARGET_VAR].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train the model\n",
    "model_pipeline = Pipeline([\n",
    "    ('med_impute', SimpleImputer(strategy='median')),\n",
    "    ('model', RandomForestRegressor(\n",
    "        criterion='mse',\n",
    "        n_estimators=100, \n",
    "        max_depth=10,\n",
    "        random_state=36\n",
    "    ))\n",
    "])\n",
    "model_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions and look at key performance metrics\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "print(\"R2\", r2_score(y_test, y_pred))\n",
    "print(\"MSE\", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE\", mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the non-profit's request, we did not include any race variables in training our model. We want to figure out whether the model is still making decisions based on race using proxy variables that can indirectly indicate race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### <span style=\"color:green\">*Activity*</span>\n",
    "\n",
    "> Work independently for 20-25 minutes. Start here and stop where \"end of activity\" is indicated\n",
    "\n",
    "**<span style=\"color:green\">To what extent are any of the feature variables in our model acting as proxies for race? Take some time to explore the data.</span>**\n",
    "\n",
    "<span style=\"color:green\">First, let's look for correlations between our feature variables and our race variables.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_modeling.loc[:, FEATURE_VARS + race_cols].corr().loc[FEATURE_VARS, race_cols]\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "sns.heatmap(corr, vmin=-1.0, vmax=1.0, cmap=\"RdBu_r\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:green\">Takeaways</span>** \n",
    "\n",
    "- <span style=\"color:green\">*Example takeaway:* poverty rate has a strong correlation with multiple race variables. It tends to be higher for tracts with a higher percent hispanic, and also higher but slightly less so for tracts with a higher percent African American. It tends to be lower in neighborhoods that are more white.</span>\n",
    "\n",
    "- <span style=\"color:green\">... your thoughts here ...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">We can use the correlation function's documentation to help with interpretation (below). You may want to look online for more details about any concepts in the documentation that you aren't familiar with, like pearson correlation coefficients.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see documentation of the df.corr function\n",
    "?df.corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">Your turn to code!</span>\n",
    "\n",
    "<span style=\"color:green\">We have a lot of different race variables, some of which have fairly low rates in many areas. **What happens if we create an aggregated variable for the percent of all non-white residents (`pct-non-white`)? What do the feature variable correlations look like for `pct-non-white` compared to `pct-white`, and do any patterns become clearer?** *Hint:* You can accomplish most of this by reusing code from above.</span>\n",
    "\n",
    "<span style=\"color:green\">Remember to document any substantive choices you have to make when you define the `pct-non-white` variable, and who is included.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pct-non-white variable\n",
    "df_modeling[\"pct-non-white\"] = ...  ## YOUR CODE HERE\n",
    "\n",
    "# plot correlations to feature variables\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:green\">Takeaways</span>** \n",
    "\n",
    "- <span style=\"color:green\">... your thoughts here ...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">Another strategy is to fit a model that predicts the percent of a given race based on feature variables. If that model performs well, we know that our model for eviction could also make accurate inferences about racial breakdowns within tracts.</span>\n",
    "\n",
    "<span style=\"color:green\">**Below, train a model that predicts `pct-white` based on the same `FEATURE_VARS` used to train our eviction model earlier. Then assess how well the model performs, and write up a few takeaways about what that means for race proxy variables in our eviction model.** Remember, you can reuse code from earlier steps.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X_train, y_train, X_test, and y_test\n",
    "# we can use the same split as before\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model to predict pct-white\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate simple performance metrics (R2, MSE, MAE)\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for any other exploration of model performance you'd like to do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:green\">Takeaways</span>** \n",
    "\n",
    "<span style=\"color:green\">... add your thoughts here ...</span>\n",
    "\n",
    "\n",
    "<span style=\"color:green\">**End of activity, wait for group to reconvene and discuss**</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">*Discussion*</span>\n",
    "\n",
    "<span style=\"color:green\">What are some approaches we can use to answer this question? Think about things like:</span> \n",
    "\n",
    "- <span style=\"color:green\">How does the format of the data about race impact our strategy?</span> \n",
    "\n",
    "- <span style=\"color:green\">What model performance metrics do we want to consider?</span> \n",
    "\n",
    "- <span style=\"color:green\">What visuals do we want to produce?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### <span style=\"color:green\">*Activity*</span>\n",
    "\n",
    "> Work independently for 15-20 minutes. Start here and stop where \"end of activity\" is indicated\n",
    "\n",
    "<span style=\"color:green\">Calculate the correlation between each of the race variables in the model with error and absolute error. Remember that you can re-use code from previous sections.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns to df_test for error and absolute error\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "# calculate correlation\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "# plot correlation heatmap\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:green\">Takeaways</span>** \n",
    "\n",
    "- <span style=\"color:green\">... add your thoughts here ...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">Generate at least one other visual that helps to compare error rates between different racial groups. You could also explore another method of determining whether error is dependent on race percentages, such as fitting another model.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**End of activity, wait for group to reconvene and discuss**</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Random Forest model above, we used `mse` (mean-squared error) as the loss function. Mean-squared error is affected more by outliers than mean-absolute error. We won't go into metric selection in detail in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go into explainability in detail in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline.named_steps[\"model\"].feature_importances_\n",
    "feature_importance = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"features\": FEATURE_VARS,\n",
    "        \"importance\": model_pipeline.named_steps[\"model\"].feature_importances_,\n",
    "    }\n",
    ")\n",
    "print(\n",
    "    feature_importance.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **D.5 Communicate bias**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go into communicate bias in detail in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **E.1 Monitoring and evaluation:** How are we planning to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">*Discussion*</span>\n",
    "\n",
    "\n",
    "<span style=\"color:green\">*E.1 and E.2:* Think about how you could monitor/evaluate the model moving forward, and put steps for redress in place.</span>\n",
    "\n",
    "- <span style=\"color:green\">What are some possible real-world consequences of the model performing poorly / making mistakes? What is the potential harm or inequity from incorrect model estimates?</span>\n",
    "\n",
    "- <span style=\"color:green\">How might you determine what the performance cutoff is for the model being good enough to use in practice?</span>\n",
    "\n",
    "- <span style=\"color:green\">What metric could you use for the above? What are some of the pros and cons of different matrics? Think about the consequences of false positives vs. false negatives in practice. Is one less desirable than the other, and how can that be reflected in your metric?</span>\n",
    "\n",
    "- <span style=\"color:green\">If/when the model is deployed in practice, will there be any human review of the model's decisions? In which cases will there be human review, and how will that be integrated?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go into roll back in detail in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go into unintended use in detail in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Science Ethics Checklist generated with [deon](http://deon.drivendata.org).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
