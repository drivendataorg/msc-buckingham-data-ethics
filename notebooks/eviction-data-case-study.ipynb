{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Ethics Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for the Eviction Data Case Study exercise in the \"Actionable Ethics for Data Scientists\" workshop for the data science MSc at the University of Buckingham. We will be walking through data and deon ethics checklist in the notebook. \n",
    "\n",
    "We will not discuss every item on the deon checklist - items have been chosen that illustrate interesting points or coding challenges. In a real world settings, you'll want to integrate the full deon checklist into your coding. You can see an example of this in the workshop repository.\n",
    "\n",
    "We will have a group discussion or activity where there is a <span style=\"color:green\">**\\*\\*bolded green heading for \"Activity\" or \"Discussion\"\\*\\***</span>. Some code relevant to the checklist items are provided, but you are encouraged to think of other things to look at and share with the group.\n",
    "\n",
    "> The goal of this notebook exercise is to practice integrating the deon checklist into your code, and to learn how to use a few basic data science tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the past five decades, [housing costs have risen faster than incomes](http://www.jchs.harvard.edu/state-nations-housing-2018), low-cost housing has been disappearing from the market, and racial disparities in homeownership rates have deepened. This has put many in a perilous situation. As the [Eviction Lab](https://evictionlab.org/why-eviction-matters/#affordable-housing-crisis) explains:\n",
    "\n",
    "> Today, most poor renting families spend at least half of their income on housing costs, with one in four of those families spending over 70 percent of their income just on rent and utilities. Only one in four families who qualify for affordable housing programs get any kind of help. Under those conditions, it has become harder for low-income families to keep up with rent and utility costs, and a growing number are living one misstep or emergency away from eviction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A non-profit dedicated to helping people at risk of eviction in California has tasked us to build a model to estimate the number of eviction cases by geography, based on socioeconomic data. They would like to use these estimates to help them prioritize where to commit funding and resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a subset of the eviction dataset published by the [Eviction Lab](https://evictionlab.org/) at Princeton University. The subset is the census-tract-level aggregates for only tracts in the state of California. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "Import necessary python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import wget\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://drivendata-public-assets.s3.amazonaws.com/odsc-west-2019/california-tracts.csv\"\n",
    "DATA_PATH = \"../data/raw/california-tracts.csv\"\n",
    "\n",
    "# Set standard fig size for plots\n",
    "FIGSIZE = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_PATH):\n",
    "    # Download data\n",
    "    wget.download(url=DATA_URL, out=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"\\nData types:\\n\", df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = non-NaN observations; size = all observations\n",
    "df.groupby(\"year\").agg(\n",
    "    count=(\"eviction-rate\", \"count\"), size=(\"eviction-rate\", \"size\")\n",
    ").transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Dictionary\n",
    "DATA_DICT_URL = \"https://drivendata-public-assets.s3.amazonaws.com/odsc-west-2019/DATA_DICTIONARY.txt\"\n",
    "DATA_DICT_PATH = \"../references/DATA_DICTIONARY.txt\"\n",
    "\n",
    "if not os.path.exists(DATA_DICT_PATH):\n",
    "    # Download data dictionary\n",
    "    wget.download(url=DATA_DICT_URL, out=DATA_DICT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $DATA_DICT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not directly collecting any data from human subjects. We are using a well-known, publicly published dataset published by a well-known research laboratory at a prestigious research university. The university has strong data protection guidelines documented [here](https://ria.princeton.edu/research-data-security). Furthermore, the data represents public records such as court records and census data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sources are reported by Eviction Lab [here](https://evictionlab.org/help-faq/#data-source). In their [methodology details](https://evictionlab.org/docs/Eviction%20Lab%20Methodology%20Report.pdf), they note that some observations are marked as \"low\", meaning that Eviction Lab believes they are undercounted based on comparisons against county-level aggregate data reported by states. \n",
    "\n",
    "There has also been some further criticism from housing activists that Eviction Lab is undercounting evictions when compared against data from local activist organizations, especially informal evictions that don't go through the formal legal process. See:\n",
    "\n",
    "1. https://shelterforce.org/2018/08/22/eviction-lab-misses-the-mark/\n",
    "2. https://chieforganizer.org/2018/08/28/the-cracks-in-the-eviction-lab-wall-are-undercounting-the-crisis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are using is aggregated at the census tract level and does not directly have PII in it. The Eviction Lab has individual household data but does not make those available publicly. Again, the university has strong data protection guidelines documented [here](https://ria.princeton.edu/research-data-security).\n",
    "\n",
    "More generally, one potential pitfall is that in situations where groups are very small, there is potential to infer or associate information to individuals. We can actually see in the data that some tracts have very small counts of renter households. However, we don't have any PII-relevant fields in this dataset, and identification in this case would involve joining to other datasets that could independently be used to identify people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how possible is it to de-anonymize the data? How many small tracts do we have?\n",
    "df[\"renter-occupied-households\"].describe(percentiles=[0.001, 0.01, 0.05, 0.10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **A.4 Downstream bias mitigation:** Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have information about the racial makeup of each tract in the data. This means that after we fit our model, we can assess whether model performance varies strongly between different racial groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Data Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using a public dataset, this is not applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using a public dataset and not collecting data from subjects directly, this is not applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using a public dataset, this is not applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted in A.2, there may be systemic undercounting of evictions due to the data collection process. In particular, for informal evictions that bypassed the formal legal process, there may be certain groups of people that an analysis based on this dataset is completely blind to. \n",
    "\n",
    "As a general rule, **any program should get significant input from the communities it is hoping to serve.** The individuals in these communities are always the best experts on their own needs. Transferring agency as much as possible to those in relevant communities helps to ensure a program is responding to real, everyday needs within a community. This is particularly relevant to consider if those administer or managing a program are not representative of the communities the program aims to serve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">*Activity TODO either remove or polish*</span>\n",
    "\n",
    "<span style=\"color:green\">**\\*\\*Discussion: What are possible sources of bias? Take some time to explore the data.\\*\\***</span> \n",
    "\n",
    "- first think about what strategies you could use. what do you want to look for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Proportion of observations with low-flag: {df['low-flag'].mean():.2f}\")\n",
    "print(\"Count of observations with low-flag\")\n",
    "df[\"low-flag\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Proportion of observations with imputed flag: {df['imputed'].mean():.2f}\")\n",
    "print(\"Count of observations with imputed flag\")\n",
    "df[\"imputed\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"evictions_is_na\"] = df[\"evictions\"].isna()\n",
    "print(f\"Proportion of Evictions Counts that are NA: {df['evictions_is_na'].mean():.2f}\")\n",
    "df[\"evictions_is_na\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "corr = df.loc[:, [col for col in df.columns if col not in (\"GEOID\", \"name\")]].corr()\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "sns.heatmap(corr, vmin=-1.0, vmax=1.0, cmap=\"RdBu_r\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_cols = [\n",
    "    \"pct-white\",\n",
    "    \"pct-af-am\",\n",
    "    \"pct-hispanic\",\n",
    "    \"pct-am-ind\",\n",
    "    \"pct-asian\",\n",
    "    \"pct-nh-pi\",\n",
    "    \"pct-multiple\",\n",
    "    \"pct-other\",\n",
    "]\n",
    "df[race_cols].describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pairwise correlation of some columns against race percentage columns\n",
    "cols_to_correlate = [\"evictions\", \"median-household-income\", \"imputed\", \"low-flag\"]\n",
    "correlation_df = (\n",
    "    df[race_cols + cols_to_correlate].corr().loc[race_cols, cols_to_correlate]\n",
    ")\n",
    "correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the above correlations.\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "sns.heatmap(\n",
    "    correlation_df.sort_values(\"evictions\"),\n",
    "    annot=True,\n",
    "    fmt=\"g\",\n",
    "    cmap=\"RdBu_r\",\n",
    "    vmin=-0.5,\n",
    "    vmax=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not going to spend time in this exercise looking at examples of poor visualizations, but this is a good check to do for real projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly not applicable. We have no PII, but we do have some tracts with few observations. We need to be mindful of those and maybe exclude them from visualizations or combine them with neighboring tracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, all of our code is contained in this notebook. For real projects, this is an important point to consider in more depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-profit wants their decision-making to be race-blind, so they ask for the population race percentage features to not be included in the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VAR = \"evictions\"\n",
    "FEATURE_VARS = [\n",
    "    \"year\",\n",
    "    \"population\",\n",
    "    \"poverty-rate\",\n",
    "    \"median-property-value\",\n",
    "    \"renter-occupied-households\",\n",
    "    \"pct-renter-occupied\",\n",
    "    \"median-gross-rent\",\n",
    "    \"median-household-income\",\n",
    "    \"rent-burden\",\n",
    "    ## Don't include race features\n",
    "    #'pct-white' , 'pct-af-am', 'pct-hispanic', 'pct-am-ind',\n",
    "    #'pct-asian', 'pct-nh-pi', 'pct-multiple', 'pct-other'\n",
    "    ## Also don't include features directly related to the target variable\n",
    "    # 'eviction-filings', 'eviction-rate', 'eviction-filing-rate'\n",
    "]\n",
    "GROUP_VAR = \"GEOID\"  # Prevent leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original Shape: {df.shape}\")\n",
    "# Drop NAs in target variable\n",
    "df_modeling = df.dropna(subset=[TARGET_VAR]).copy()\n",
    "df_modeling.reset_index(inplace=True)\n",
    "print(f\"Shape without NAs: {df_modeling.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit, cross_validate\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling.loc[:, TARGET_VAR].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train-test split for model evaluation later\n",
    "split = GroupShuffleSplit(test_size=0.20, n_splits=2, random_state=36).split(\n",
    "    df_modeling, groups=df_modeling.loc[:, GROUP_VAR]\n",
    ")\n",
    "\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "df_train = df_modeling.loc[train_inds, :]\n",
    "df_test = df_modeling.loc[test_inds, :]\n",
    "\n",
    "X_train = df_train.loc[:, FEATURE_VARS].values\n",
    "y_train = df_train.loc[:, TARGET_VAR].values\n",
    "\n",
    "X_test = df_test.loc[:, FEATURE_VARS].values\n",
    "y_test = df_test.loc[:, TARGET_VAR].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train the model\n",
    "model_pipeline = Pipeline([\n",
    "    ('med_impute', SimpleImputer(strategy='median')),\n",
    "    ('model', RandomForestRegressor(\n",
    "        criterion='mse',\n",
    "        n_estimators=100, \n",
    "        max_depth=10,\n",
    "        random_state=36\n",
    "    ))\n",
    "])\n",
    "model_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions and look at key performance metrics\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "print(\"R2\", r2_score(y_test, y_pred))\n",
    "print(\"MSE\", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE\", mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the non-profit's request, we did not include any race variables in training our model. We want to figure out whether the model is still making decisions based on race using proxy variables that can indirectly indicate race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### <span style=\"color:green\">*Activity*</span>\n",
    "\n",
    "> Work independently for 20-25 minutes. Start here and stop where \"end of activity\" is indicated\n",
    "\n",
    "**<span style=\"color:green\">To what extent are any of the feature variables in our model acting as proxies for race? Take some time to explore the data.</span>**\n",
    "\n",
    "<span style=\"color:green\">First, let's look for correlations between our feature variables and our race variables.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_modeling.loc[:, FEATURE_VARS + race_cols].corr().loc[FEATURE_VARS, race_cols]\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "sns.heatmap(corr, vmin=-1.0, vmax=1.0, cmap=\"RdBu_r\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:green\">Takeaways</span>** \n",
    "\n",
    "- <span style=\"color:green\">*Example takeaway:* poverty rate has a strong correlation with multiple race variables. It tends to be higher for tracts with a higher percent hispanic, and also higher but slightly less so for tracts with a higher percent African American. It tends to be lower in neighborhoods that are more white.</span>\n",
    "\n",
    "- <span style=\"color:green\">... your thoughts here ...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">We can use the correlation function's documentation to help with interpretation (below). You may want to look online for more details about any concepts in the documentation that you aren't familiar with, like pearson correlation coefficients.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see documentation of the df.corr function\n",
    "?df.corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">Your turn to code!</span>\n",
    "\n",
    "<span style=\"color:green\">We have a lot of different race variables, some of which have fairly low rates in many areas. **What happens if we create an aggregated variable for the percent of all non-white residents (`pct-non-white`)? What do the feature variable correlations look like for `pct-non-white` compared to `pct-white`, and do any patterns become clearer?** *Hint:* You can accomplish most of this by reusing code from above.</span>\n",
    "\n",
    "<span style=\"color:green\">Remember to document any substantive choices you have to make when you define the `pct-non-white` variable, and who is included.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pct-non-white variable\n",
    "df_modeling[\"pct-non-white\"] = ...  ## YOUR CODE HERE\n",
    "\n",
    "# plot correlations to feature variables\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:green\">Takeaways</span>** \n",
    "\n",
    "- <span style=\"color:green\">... your thoughts here ...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">Another strategy is to fit a model that predicts the percent of a given race based on feature variables. If that model performs well, we know that our model for eviction could also make accurate inferences about racial breakdowns within tracts.</span>\n",
    "\n",
    "<span style=\"color:green\">**Below, train a model that predicts `pct-white` based on the same `FEATURE_VARS` used to train our eviction model earlier. Then assess how well the model performs, and write up a few takeaways about what that means for race proxy variables in our eviction model.** Remember, you can reuse code from earlier steps.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X_train, y_train, X_test, and y_test\n",
    "# we can use the same split as before\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model to predict pct-white\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate simple performance metrics (R2, MSE, MAE)\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for any other exploration of model performance you'd like to do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:green\">Takeaways</span>** \n",
    "\n",
    "<span style=\"color:green\">... add your thoughts here ...</span>\n",
    "\n",
    "\n",
    "<span style=\"color:green\">**End of activity, wait for group to reconvene and discuss**</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">*Discussion*</span>\n",
    "\n",
    "<span style=\"color:green\">What are some approaches we can use to answer this question? Think about things like:</span> \n",
    "\n",
    "- <span style=\"color:green\">How does the format of the data about race impact our strategy?</span> \n",
    "\n",
    "- <span style=\"color:green\">What model performance metrics do we want to consider?</span> \n",
    "\n",
    "- <span style=\"color:green\">What visuals do we want to produce?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### <span style=\"color:green\">*Activity*</span>\n",
    "\n",
    "> Work independently for 15-20 minutes. Start here and stop where \"end of activity\" is indicated\n",
    "\n",
    "<span style=\"color:green\">Calculate the correlation between each of the race variables in the model with error and absolute error. Remember that you can re-use code from previous sections.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns to df_test for error and absolute error\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "# calculate correlation\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "# plot correlation heatmap\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:green\">Takeaways</span>** \n",
    "\n",
    "- <span style=\"color:green\">... add your thoughts here ...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">Generate at least one other visual that helps to compare error rates between different racial groups. You could also explore another method of determining whether error is dependent on race percentages, such as fitting another model.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**End of activity, wait for group to reconvene and discuss**</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Random Forest model above, we used `mse` (mean-squared error) as the loss function. Mean-squared error is affected more by outliers than mean-absolute error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline.named_steps[\"model\"].feature_importances_\n",
    "feature_importance = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"features\": FEATURE_VARS,\n",
    "        \"importance\": model_pipeline.named_steps[\"model\"].feature_importances_,\n",
    "    }\n",
    ")\n",
    "print(\n",
    "    feature_importance.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **D.5 Communicate bias**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **E.1 Monitoring and evaluation:** How are we planning to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">*Discussion*</span>\n",
    "\n",
    "\n",
    "<span style=\"color:green\">Think about how you could monitor/evaluate the model moving forward.</span>\n",
    "\n",
    "- <span style=\"color:green\">What are some possible real-world consequences of the model performing poorly / making mistakes?</span>\n",
    "\n",
    "- <span style=\"color:green\">How might you determine what the performance cutoff is for the model being good enough to use in practice?</span>\n",
    "\n",
    "- <span style=\"color:green\">What metric could you use for the above? What are some of the pros and cons of different matrics? Think about the consequences of false positives vs. false negatives in practice. Is one less desirable than the other, and how can that be reflected in your metric?</span>\n",
    "\n",
    "- <span style=\"color:green\">If/when the model is deployed in practice, will there be any human review of the model's decisions? In which cases will there be human review, and how will that be integrated?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is important to consider in the context of how analysis and model results are used. Are the results used to make positive or negative interventions? What is the potential harm or inequity from incorrect model estimates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Science Ethics Checklist generated with [deon](http://deon.drivendata.org).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
